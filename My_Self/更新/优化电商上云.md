澳洲小的电商企业客户，因为业务增长的需求，他们想整体迁移上云，并逐步采用 PaaS、SaaS 服务。然后我接到这个case的最开始的问题，是一个类似咨询的问题，想咨询我们迁移的一些建议，包括如何给VM迁移，数据库迁移等等，然后我们对接的是客户的技术团队和他们的CSA团队，主要是负责给他们迁移这一块做一个技术咨询和支持的服务。然后客户他们的环境是本地自建IDC，大约有20台VM。

## 前期规划与基础落地
前期迁移前的时候，他们是在azure先landing一些基础底座，这一部分是我们CSA团队负责的，其中我觉得学到最大的是帮客户搭建基于VNet的Hub–Spoke网络，印象中他们是搭了三个VNet网，包含一个hub VNet，里面是放一些Baston跳板机，firewall/NVA之类的hub组件，Hub通过NAT Gateway统一egress IP，Spoke-Data 一般不出网，baston跳板机，供运维从浏览器安全登录各 Spoke VM/跳板机，无需给 VM 开公网，IP这个子网就是集中管理路由和网络策略，然后有两个spoke VNet，一个放核心应用，一个放核心数据服务，Spoke 之间默认隔离，三者之间用VNet Peering联通， 然后确保之间是按需放通流量，确保最小访问。然后包括他的**paas**都建了private endpoint，配置的private dns都链接到三个VNet，让 Spoke 内的 App/容器访问 Blob、MySQL Flexible、Redis、AI Search 等 Private Endpoint 时走内网解析，流量全走内网。关于监控部分，各 Spoke 的 VM/容器/数据库代理将指标与日志汇聚到 Log Analytics Workspace，结合 Azure Monitor + App Insights 做仪表盘、告警与追踪。

## 安装并配置 Azure Migrate Appliance，对本地 VM 环境进行发现与评估：
然后就是通过azure migrate去评估，关于性能评估，我们用的是performance-based，按照当前的CPU/内存利用率，还有磁盘IOPS/吞吐去计算，得出一个推荐的azure sku，简单来说azure migrate会通过appliance去收集数据，比如vmware是每20s，hyper-V是每30s取样创建一个数据点，然后每10分钟聚合成一个峰值点，然后发送到Azure migrate。评估期一般是一周到一个月不等，按照客户设置的百分位利用率(常用P95,95百分位)取代标点，再乘以安全系数(1.3-2.0不等)去给出推荐规格。比如客户当时有一个16vCPU的服务器，然后根据性能数据样本去按照升序排序，然后最终评估出该服务器在第95百分位内仅利用了20%的可用CPU，因此其实只需要4vCPU就足以支持它的负载，然后最后客户确定了一个安全系数为2，我们最终得出的建议是8核vCPU，当然还会有关于Azure Readiness的评估，比如会去判断服务器的Windows版本是不是过低，或者是有服务器磁盘超过64TB也无法支持直接迁移上云等，然后azure migrate会给相应的remediation guidance在迁移前去该升级升级，该修复修复。当然我们还会根据azure migrate产出的依赖图去做一个成组迁移清单，因为当时客户体系比较紧凑，各个组件之间强相关性，所以我们是和他们CSA团队建议先做一个整体迁移，后续再去做云上优化。然后迁移的时候我们是通过私网迁移，数据完全不走公网，主要是通过走ExpressRoute，并通过在Azure这边给recovery service vault创建private endpoint，然后给本地配置好private endpoint的DNS解析这样，但是控制面任然需要走Azure Migrate的公网服务端点(443出站)，因此还是需要给需要的公网域名白名单和代理策略放行。期间我们是先后进行了一次测试迁移，确保迁移上云后应用之间能正常工作，包括测试是否能正常启动/登录啊，检查磁盘可见，数据盘序号啊挂载点是否一致啊，测试依赖端口的连通性啊，web到api，检查DNS解析啊等等。然后最终我们才开始正式的迁移，当然迁移的背后，azure migrate会做一个叫hydration的过程，简单来说就是azure会临时起一台中介VM，把源盘挂上然后对驱动啊，代理什么的做必要的改动，再生成最终的VM。然后就是正式迁移了，正式迁移的过程中，就是要确保把业务域名更换到客户云上的frontdoor等，当然最后最重要的数据库迁移，就还是会有一个短暂的停机，并且再迁移前会做一次last sync，确保数据一致性，然后再正式迁移。因为我们是在他们美国团队的晚上去进行的，所以是用户活跃度最低的时候去做的迁移，大致的宕机窗口是10分钟左右。

## 存储与对象数据迁移
- 本地 4 台 MinIO Storage 服务器迁移至 Azure Blob (ADLS Gen2)，并开启版本管理、软删除与生命周期策略。
- 采用 Azure Data Box 离线迁移 80TB 存量数据，结合 AzCopy 做增量与后续同步。
- 应用层启用 双写机制（先写 Blob，再异步写 FastDFS），通过 Front Door 回源机制 实现平滑切换与快速回滚。完成一致性校验与观察窗口后，逐步停写、切只读，最终下线本地 FastDFS。

## 网络与边缘层替代
- 本地边缘 Nginx/HAProxy 替换为 Azure Front Door Premium（自带 CDN 与 WAF），实现全球加速、负载均衡与应用层防护。

## 数据库与缓存迁移
- MySQL 主从数据库通过 DMS 在线迁移至 Azure Database for MySQL Flexible Server（ZRS 高可用），迁移过程中使用全量+持续复制，低峰期短暂冻结写入完成连接切换与验证。
- Redis 先以旁路缓存方式引入 Azure Cache for Redis (Premium)，逐步提升命中率并切换读写路径，替代本地 2 台 Redis。

## 应用与容器化改造
- 无状态 Web App 直接迁移至 App Service 与 Container Apps，结合 Deployment Slot/Revision 实现灰度与金丝雀发布。
- 静态前端迁移至 Azure Static Web Apps，降低成本与加速交付。
- 第二阶段规划进一步引入 AKS (Azure Kubernetes Service)，支撑更复杂的微服务与容器编排需求。

## 成果与价值
- 实现业务整体从本地 IDC 向 Azure 平稳迁移，确保业务连续性与数据一致性；
- 替换存储、缓存、负载均衡等高运维负担组件为云端托管服务，显著降低运维压力与成本；
- 上云后应用具备更强弹性扩展与高可用能力，为后续多 Region 容灾与 AKS 微服务化演进打下基础。

