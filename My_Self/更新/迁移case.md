客户是一个微软unified的大客户，好像是一个澳洲比较大的制造业的企业，然后本地有分别两套vSphere/Hyper-V集群托管有超过300+VM，应用以Web层，一些静态资源，nginx啊等等，然后还有一层应用层，包括他们有大量服务器部署python等api的微服务还有一些api网管，redis和一些日志服务器等，还有数据层包括他们用的oracle数据库，postgreql等等。和少量中间件为主，然后他们希望变更窗口越短越好，那我们是和他们的微软架构师团队和他们的技术团队主要包括VM集群的管理运维团队和他们的网络团队等对接，然后就是通过azure migrate去评估，关于性能评估，我们用的是performance-based，按照当前的CPU/内存利用率，还有磁盘IOPS/吞吐去计算，得出一个推荐的azure sku，简单来说azure migrate会通过appliance去收集数据，比如vmware是每20s，hyper-V是每30s取样创建一个数据点，然后每10分钟聚合成一个峰值点，然后发送到Azure migrate。评估期一般是一周到一个月不等，按照客户设置的百分位利用率(常用P95,95百分位)取代标点，再乘以安全系数(1.3-2.0不等)去给出推荐规格。比如客户当时有一个16vCPU的服务器，然后根据性能数据样本去按照升序排序，然后最终评估出该服务器在第95百分位内仅利用了20%的可用CPU，因此其实只需要4vCPU就足以支持它的负载，然后最后客户确定了一个安全系数为2，我们最终得出的建议是8核vCPU，当然还会有关于Azure Readiness的评估，比如会去判断服务器的Windows版本是不是过低，或者是有服务器磁盘超过64TB也无法支持直接迁移上云等，然后azure migrate会给相应的remediation guidance在迁移前去该升级升级，该修复修复。当然我们还会根据azure migrate产出的依赖图去做一个成组迁移清单，把一些强依赖集群，规划成一组迁移，记得当时客户是分3次迁移，前面一批就是一些无状态的Web、静态站、API网管、跳板机啊等等，其中这一批有很大部分客户是直接在azure上部署paas服务了，就没有走迁移的路线，所以原本本地有80多台无状态的服务器，可能最后上云的就减半了，然后第二波就是一些中间件像redis，rabbitMQ等，业务的api等等，去进行迁移，最后一波就是把核心的数据库，然后迁移的时候我们是通过私网迁移，数据完全不走公网，主要是通过走ExpressRoute，并通过在Azure这边给recovery service vault创建private endpoint，然后给本地配置好private endpoint的DNS解析这样，但是控制面任然需要走Azure Migrate的公网服务端点(443出站)，因此还是需要给需要的公网域名白名单和代理策略放行。期间我们是先后进行了一次测试迁移，确保迁移上云后应用之间能正常工作，包括测试是否能正常启动/登录啊，检查磁盘可见，数据盘序号啊挂载点是否一致啊，测试依赖端口的连通性啊，web到api，检查DNS解析啊等等。然后最终我们才开始正式的迁移，当然迁移的背后，azure migrate会做一个叫hydration的过程，简单来说就是azure会临时起一台中介VM，把源盘挂上然后对驱动啊，代理什么的做必要的改动，再生成最终的VM。然后就是正式迁移了，正式迁移的过程中，因为是分批迁移，所以要确保先迁移上去的web vm啊，api啊还能和本地数据库连接，以及就是要确保把业务域名更换到客户云上的frontdoor等，当然最后最重要的数据库迁移，就还是会有一个短暂的停机，并且azure migrate再迁移前会做一次last sync，确保数据一致性，然后再正式迁移。因为我们是在他们美国团队的晚上去进行的，所以是用户活跃度最低的时候去做的迁移，大致的宕机窗口是20分钟左右。

遇到的问题：
当时一开始卡在私网复制出了问题，一开始是azure终端的private endpoint不联通，一开始客户一直出问题的原因是他们在dns中加了一个forwarder到azure的public dns ip 168.63.129.16，然后一直还是nslookup出问题，当时我们因为迁移窗口短，所以是直接到host file上加映射IP和地址解决的，然后当时解决了PE解析的问题以后，最多的问题还是disk churn/iops超了限制，那么我们就是要去切换成high churn模式，把缓存数据的cache storage account改成premium block blob，这样单机可提升到100MB/s，当然还是有部分VM尤其是数据库本地磁盘churn太高了，我们当时就把复制压力分散到多个存储账户，避免单个账户的入口限速，当然还有一些磁盘就是高写入，那我们只能先去排除掉这些高churn磁盘，然后再做迁移，事后再去把剩余几个高churn的磁盘去单独做数据传输，除了单个disk churn的问题，还有就是客户本地单个appliance的带宽不够，所以其实当时是横向增加了三台appliance，然后才解决了单个appliance的带宽不够的问题。
