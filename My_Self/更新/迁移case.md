可以的，我们的团队是负责对微软云迁移和融灾、备份方向的技术支持。所以有非常多相关的迁移案例，和当前阿里云的架构师岗位有非常多强相关的地方。那可能我印象比较深刻的一个案例，就是在我们当时刚刚对接微软云的Premium客户的时期的一个澳洲的制造企业。那么当时我们接到这个案例的时候，还是一个初期的阶段，架构师团队还在跟客户确认其当前架构，业务和上云目标的一个阶段。然后当时客户环境是双栈虚拟化包含VMware和Hyper-V的虚拟机将近300多台VM。我们是从一个技术支持的目标出发和客户微软架构师团队和客户的虚拟化、网络、运维团队去进行一个对接，提供关于微软云迁移产品的技术咨询和解决方案的服务。初期，我们会和架构师团队去统一迁移的部分口径，包括客户当前整体架构，测试/正式迁移的周期，是否需要稳定回退方案，还包括一些数据安全合规，以及迁后优化等事项，也包含具体的RTO和RPO的指标等。

那么迁移前，我们会协助客户使用微软Migrate中的assertment评估工具去对它当前架构做基线评估，我们会通过在客户本地部署的Azure迁移服务器，去收集虚机的数据包括但不限于CPU利用率、磁盘的IO读写等等。按照P95性能样本再加上客户确认的安全系数，得出一个推荐Azure虚机的SKU。除此之外，评估还会包括本地机器的Azure Readiness清单，大致意思就是就绪性整改清单，因为最终客户本地机器是要上云，云上虚机会有一些支持范围，包括不能支持太老的OS版本，或者是对磁盘大小有一些限制，此清单会评估客户本地虚机的一些改造列表。最后也会产出他本地的依赖图，基于依赖图可以建议客户把系统分波次迁移，从先无状态与可PaaS替代的Web/静态/跳板机作为第一波迁移对象，那第二波可以是一些中间件与业务API，最后也是最重要的是核心数据库的迁移。那么可能我们整体的目标方案采用一个专线Express route加上云上的private endpoint的数据接收终端，所以相当于数据面采用私网复制，控制面最小放通关于一些公有终端的443端口。

那么还有就是landing的部分，这部分是架构师负责，我们是在会议中standby。这一步主要是架构师帮助客户landing一些云上网络基座，架构师团队使用我们微软云的Azure Front Door，一个L7的包含CDN和防火墙的设备，这个设备后期会作为一个统一本地和云端的流量入口，一直支持到后期可能的阶段性双活，那么也包括他后期割接的时候，会采用一个灰度或者蓝绿的回滚方案。再到搭建复制链路，这一步我们会协助客户在本地部署ASR/迁移Appliance，微软对VMware和Hyper-V是通过基于VMware的CBT，Hyper-V侧用HRL日志跟踪去实现一个无代理方式的迁移，初始做全量备份，然后做增量备份去做到数据一致性。关于复制周期，我们采用的是基于上次增量备份耗时的一半，最短不低于1小时，以及最长不超过12小时，这大概是我们底层实现的一个基本逻辑。那么在正式迁移前，我们会走一遍测试迁移，我们需要确保测试迁移过程中，测试虚机能成功创建，那么在之后的测试阶段，主要是客户团队去校验一些基础的虚机功能包括简单的是否能够通过域账号SSH/RDP启动、检查虚机上的挂盘序号、依赖端口，api之间是否能正常调用与DNS能不能通过等等。测试迁移完成之后，会进入正式迁移阶段。对于Azure迁移虚机的正式迁移阶段，我们会进行一次最后同步，并通过关停源端防止新数据写入，避免数据无法一致性问题，大概产生20分钟的一个停机窗口。

当然，过程中肯定不会像我上面说的那么流畅，我们肯定是遇到了非常多大大小小的问题，因为时间关系，我就挑其中我印象比较深刻的一到两个问题来回答。第一个就是客户他们有部分比较老的应用，底层代码是通过硬编码基于IP通信和互相调用，但是之后客户本地和云端是要通过专线打通，那么云端IP和本地IP网段肯定是不能overlap重合的，此时面临的问题就是虚机上云后这个IP发生变化了，那代码中还在去尝试调用旧IP，肯定就会出现调用失败的情况。那我们当下，基于之前迁移案例经验，给到他们开发团队的建议是使用FQDN，域名的方式去替代硬编码。那客户这边是不同意的，他们不希望在迁移前后去对本地做大规模的改造，尤其是在生产环境中。所以我们当下给到另一个方案，就是通过本地防火墙中设置一个DNAT和SNAT规则，将旧IP指向云端新IP，并通过修改路由表将虚机下一跳到防火墙，这一步也需要确保本地防火墙可以和云端内部负载均衡器之前通过专线能互相访问。确保客户完成迁移之后，应用还是能通过旧IP去进行交流。那么这个其实只是也只是一个现阶段为了保证迁移后应用能正常运行的临时方案，未来客户上云，还是建议他们去把他的底层代码使用FQDN替换IP。

落地过程中有三类典型挑战。我方快速闭环：其一是私网解析，一开始客户把Forwarder指向168.63.129.16导致PE不通，窗口期先以Hosts应急，随后用Private DNS Zone+条件转发长期修复；其二是IP变更导致耦合，优先以FQDN替代硬编码、降低TTL并把权威解析CNAME到Front Door，若改造成本高则在本地做DNAT/SNAT或反向代理保证回程对称；其三是高写入与带宽瓶颈，开启High-churn模式把缓存切到Premium Block Blob、分散到多存储账户并横向扩容Appliance，对极高写入的磁盘单列后置处理，同时实施分批复制与日夜限流策略。
结果方面，首波无状态工作负载大量改为PaaS，上云服务器量减半；通过右尺码、弹性与分层存储实现明显TCO优化；专线+PE+最小权限与全链路审计满足合规；分波+演练+可回退的发布策略保证窗口可控、零回滚事故。复盘看，这次是把TOGAF的“业务对齐—基线评估—目标架构—机会与方案—迁移计划—实施治理”完整工程化：先治理后迁移（账号/网络/DNS/权限基线），先演练后切换，能PaaS不硬搬迁，以数据面为王控制面最小暴露，最终实现“迁得上去、跑得稳、管得住、花得省”。
客户是一个微软unified的大客户，好像是一个澳洲比较大的制造业的企业，然后本地有分别两套vSphere/Hyper-V集群托管有超过300+VM，应用以Web层，一些静态资源，nginx啊等等，然后还有一层应用层，包括他们有大量服务器部署python等api的微服务还有一些api网管，redis和一些日志服务器等，还有数据层包括他们用的oracle数据库，postgreql等等。和少量中间件为主，然后他们希望变更窗口越短越好，那我们是和他们的微软架构师团队和他们的技术团队主要包括VM集群的管理运维团队和他们的网络团队等对接。

#### Azure Site Recovery 复制设备:
1. 设备中的所有组件都与复制设备协调。此服务负责监督所有端到端 Site Recovery 活动，包括监视受保护计算机的运行状况、数据复制、自动更新等。
2. 虚拟机会使用VMware的CBT技术去进行快照管理，然后通过端口 HTTPS 443和HTTPS 9443端口与这个复制设备appliance。进行通信，向设备发送复制数据（入站）。
3. 该设备接收复制数据，对其进行优化和加密，然后通过端口 443 将其发送到 Azure 存储。复制数据日志首先存储在 Azure 中的缓存存储帐户中。
4. 这些日志经过处理后，数据存储在 Azure 托管磁盘（称为asrseeddisk）中。恢复点将在此磁盘上创建。

#### 迁移前评估
1. performance-based，按照当前的CPU/内存利用率，还有磁盘IOPS/吞吐去计算，得出一个推荐的azure sku.
2. 简单来说azure migrate会**通过appliance去收集数据**，**比如vmware是每20s，hyper-V是每30s取样创建一个数据点**，然后每10分钟聚合成一个峰值点，然后发送到Azure migrate。
3. 评估期一般是一周到一个月不等，按照客户设置的**百分位利用率(常用P95,95百分位)取代标点，再乘以安全系数(1.3-2.0不等)**去给出推荐规格。
4. 比如客户当时有一个16vCPU的服务器，然后根据性能数据样本去按照升序排序，然后最终评估出该服务器在第95百分位内仅利用了20%的可用CPU，因此其实只需要4vCPU就足以支持它的负载，然后最后客户确定了一个安全系数为2，我们最终得出的建议是8核vCPU，
5. 当然还会有关于**Azure Readiness的评估**，比如会去判断服务器的Windows版本是不是过低，或者是有服务器磁盘超过64TB也无法支持直接迁移上云等，然后azure migrate会给相应的remediation guidance在迁移前去该升级升级，该修复修复。
6. 当然我们还会根据azure migrate**产出的依赖图**去做一个成组迁移清单，把一些强依赖集群，规划成一组迁移。

#### 底层复制技术讲解
(vmware appliance上会有data replication agent和gateway agent)
然后就是进行数据的第一次传输也叫initial replication，azure migrate第一次会给每个VM都做一次VMware snapshot，然后，通过azure appliance将快照磁盘中的完整数据副本通过HTTPS和TLS 1.2先传到云上的一个storage account，然后再通过storage account复制到目标订阅中的托管磁盘(静态加密)，初始复制完成后，会进入到增量复制的阶段，相当于基于上一次复制以来发生的所有数据更改会被打包复制并写入副本托管磁盘，确保托管磁盘数据和源VM保持同步。底层用的是VMware的CBT技术获得当前快照与上次成功的快照之间的更改，当然最后正式客户点迁移的那一刻，会最后进行一次数据校验，把剩余所有剩余的更改过的数据最后复制到托管磁盘，然后此时必须关闭本地VM，防止迁移过程有任何新增数据无法同步。
同时azure migrate也会有一个数据校验的方式，第一个是确确保每次复制周期同步上来的数据是一致性的，在增量备份阶段，我们会通过将源磁盘划分成512字节的扇区，每个扇区都映射到bitmap中的一个bit，同时，在数据传输到azure的托管磁盘后，托管磁盘也会创建一个bitmap，最后会通过对比两个bitmap，确保没有遗漏任何已更改的块，如果发现有任何不匹配的情况，当前复制周期会被视作为失败，那么在下一次复制周期，又会重新进行同步。第二个是会确保当前azure的托管磁盘与源磁盘的数据是否相同，简单来说就是每次已上传的数据都会被作为blob进行压缩和加密后存储到存储账户中，并在压缩前计算此块的校验和(checksum)，如果不匹配，则不会写入azure磁盘中，并且视为当前周期失败，和刚刚一样，在下一次复制周期，又会重新进行同步。
#### 复制周期逻辑讲解
复制周期的逻辑是先进行初次的完整复制，并在初次完整复制后马上进行第一个增量备份，下一个增量备份会通过一个公式，min[max[1 hour, (<Previous delta replication cycle time>/2)], 12 hours]，这个公式比较抽象，简单来说就是下一次周期会在上一次增量备份所花费的时间除以二，并且这个时间不会低于1小时也不会高于12小时。假如上一次增量备份花了8小时才完成，那下一次增量备份会在4小时以后进行。

#### Hydration
然后最终我们才开始正式的迁移，当然迁移的背后，azure migrate会做一个叫hydration的过程，简单来说就是azure会临时起一台中介VM，把源盘挂上然后对驱动啊，代理什么的做必要的改动，再生成最终的VM。然后就是正式迁移了，正式迁移的过程中，因为是分批迁移，所以要确保先迁移上去的web vm啊，api啊还能和本地数据库连接，以及就是要确保把业务域名更换到客户云上的frontdoor等，当然最后最重要的数据库迁移，就还是会有一个短暂的停机，并且azure migrate再迁移前会做一次last sync，确保数据一致性，然后再正式迁移。

#### Hyper-V底层机制
关于hyper-V,就是基于Hyper-V replica去追踪每次磁盘的变化数据，并记录到log files(hrl文件)，这个log文件与磁盘是在同一个文件夹当中，每个磁盘都会有一个关联的hrl文件，会发送到云端的storage account，为每次增量备份去做一个追踪。

## 遇到的问题：
#### 网络：
1. 迁移网络遇到的问题：
当时一开始卡在私网复制出了问题，一开始是azure终端的private endpoint不联通，客户一直出问题的原因是他们在dns中加了一个forwarder到azure的public dns ip 168.63.129.16，然后一直还是nslookup出问题，当时我们因为迁移窗口短，所以是直接到host file上加映射IP和地址解决的，
2. 迁移后，IP发生改变，先前使用IP互相调用的应用会失联，怎么办？
    #### 情况一：用户本地可以将IP硬编码统一改成域名：
    1. 用FQDN取代硬编码，**本地DNS**服务器做域名解析**指向本地IP**。
    2. 在云端做好Azure private DNS Zone，并打通云端DNS resolver和本地的网络，在本地DNS做conditional forwarded。
    3. 降低TTL到60-300秒，预热缓存。
    4. 迁移日，把域名的权威解析/记录切换成云端IP/Private endpoint；客户端随TTL过期后自动指向新后端。
    #### 情况二：本地全面改代码代价太大：
    ##### A. NAT转换
    1. 本地放置一台NAT/防火墙设备(F5、Palo等等)，把目的地为旧IP流量引流到NAT，然后通过NAT做DNAT规则，比如旧IP:端口号指向新IP:端口号。
    2. 为避免回程不对称，对所有DNAT规则启用SNAT，把源改成NAT侧地址。
    3. 云端确保有Expressroute/VPN，VNet到本地的路由包含本地网段，允许回程到NAT的地址。
    ##### B. 反向代理/网关：
    1. 本地部署一台网关/代理(Nginx/F5)，对外仍监听旧IP/端口，转发到云端后端。
    2. 在代理上监听旧IP：端口并且后端指向新IP：端口。
    3. 云端部署ILB，将迁移上来的应用放入后端。

#### 割接问题：
1. 简单一点，看客户需要做蓝绿，还是灰度。
2. 蓝绿则就是比较简单，比如拿azure举例子，在云端准备好一个公网入口的形态，可以是Azure Front door(全球加速 + 权重/健康探测 + WAF，推荐),Azure application gateway(区域入口，四层配合公有 SLB)或者就是简单的公有load balancer(最轻，但没有 L7 能力；灰度靠上层或 Traffic Manager)。
3. 拿AFD举例子，在AFD准备两个入口，一个是你本地的公网出口(可能是一个反代理服务器)的公网地址，一个是你的云上公网地址，割切时，将权威DNS的对外域名改成CNAME指向AFD的endpoint，之后你就可以在AFD上切换优先级，把优先级改成云上公网地址。但在这之前你还要在AFD上做一些校验和配置等等，AFD需要确保这个域名是你的。
#### disk churn：
然后当时解决了PE解析的问题以后，最多的问题还是disk churn/iops超了限制，那么我们就是要去切换成high churn模式，把缓存数据的cache storage account改成premium block blob，这样单机可提升到100MB/s，当然还是有部分VM尤其是数据库本地磁盘churn太高了，我们当时就把复制压力分散到多个存储账户，避免单个账户的入口限速，当然还有一些磁盘就是高写入，那我们只能先去排除掉这些高churn磁盘，然后再做迁移，事后再去把剩余几个高churn的磁盘去单独做数据传输，除了单个disk churn的问题，还有就是客户客户复制超过300台VM，超出了单个appliance支持的上限，需要scale out appliance。
#### 宽带压力：
就是并行复制大量磁盘时，本地带宽压力比较大，所以也是分批去进行复制，并且也是改了VMware appliance上的限流策略，白天的时候限流100Mb/s，晚上放开,Hyper-V是通过C:\Program Files\Microsoft Azure Recovery Services Agent\bin\wabadmin.msc去调整限速策略。


