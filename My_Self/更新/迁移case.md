## 背景
客户是一个微软unified的大客户，好像是一个澳洲比较大的制造业的企业，然后本地有分别两套vSphere/Hyper-V集群托管有超过300+VM，应用以Web层，一些静态资源，nginx啊等等，然后还有一层应用层，包括他们有大量服务器部署python等api的微服务还有一些api网管，redis和一些日志服务器等，还有数据层包括他们用的oracle数据库，postgreql等等。和少量中间件为主，然后他们希望变更窗口越短越好，那我们是和他们的微软架构师团队和他们的技术团队主要包括VM集群的管理运维团队和他们的网络团队等对接。

在本地要去搭建一个Azure Site Recovery 复制设备，设备中的所有组件都与复制设备协调。此服务负责监督所有端到端 Site Recovery 活动，包括监视受保护计算机的运行状况、数据复制、自动更新等。虚拟机会使用VMware的CBT技术去进行快照管理，然后通过端口 HTTPS 443和HTTPS 9443端口与这个复制设备appliance。进行通信，向设备发送复制数据（入站）。该设备接收复制数据，对其进行优化和加密，然后通过端口 443 将其发送到 Azure 存储。复制数据日志首先存储在 Azure 中的缓存存储帐户中。这些日志经过处理后，数据存储在 Azure 托管磁盘（称为asrseeddisk）中。恢复点将在此磁盘上创建。

## 迁移前评估
1. 然后就是通过azure migrate去评估，关于性能评估，我们用的是performance-based，按照当前的CPU/内存利用率，还有磁盘IOPS/吞吐去计算，得出一个推荐的azure sku，简单来说azure migrate会通过appliance去收集数据，比如vmware是每20s，hyper-V是每30s取样创建一个数据点，然后每10分钟聚合成一个峰值点，然后发送到Azure migrate。评估期一般是一周到一个月不等，按照客户设置的百分位利用率(常用P95,95百分位)取代标点，再乘以安全系数(1.3-2.0不等)去给出推荐规格。比如客户当时有一个16vCPU的服务器，然后根据性能数据样本去按照升序排序，然后最终评估出该服务器在第95百分位内仅利用了20%的可用CPU，因此其实只需要4vCPU就足以支持它的负载，然后最后客户确定了一个安全系数为2，我们最终得出的建议是8核vCPU，
2. 当然还会有关于Azure Readiness的评估，比如会去判断服务器的Windows版本是不是过低，或者是有服务器磁盘超过64TB也无法支持直接迁移上云等，然后azure migrate会给相应的remediation guidance在迁移前去该升级升级，该修复修复。
3. 当然我们还会根据azure migrate产出的依赖图去做一个成组迁移清单，把一些强依赖集群，规划成一组迁移，记得当时客户是分3次迁移，前面一批就是一些无状态的Web、静态站、API网管、跳板机啊等等，其中这一批有很大部分客户是直接在azure上部署paas服务了，就没有走迁移的路线，所以原本本地有80多台无状态的服务器，可能最后上云的就减半了，然后第二波就是一些中间件像redis，rabbitMQ等，业务的api等等，去进行迁移，最后一波就是把核心的数据库，然后迁移的时候我们是通过私网迁移，数据完全不走公网，主要是通过走ExpressRoute，并通过在Azure这边给recovery service vault创建private endpoint，然后给本地配置好private endpoint的DNS解析这样，但是控制面任然需要走Azure Migrate的公网服务端点(443出站)，因此还是需要给需要的公网域名白名单和代理策略放行。期间我们是先后进行了一次测试迁移，确保迁移上云后应用之间能正常工作，包括测试是否能正常启动/登录啊，检查磁盘可见，数据盘序号啊挂载点是否一致啊，测试依赖端口的连通性啊，web到api，检查DNS解析啊等等。

## 底层复制技术讲解
(vmware appliance上会有data replication agent和gateway agent)
然后就是进行数据的第一次传输也叫initial replication，azure migrate第一次会给每个VM都做一次VMware snapshot，然后，通过azure appliance将快照磁盘中的完整数据副本通过HTTPS和TLS 1.2先传到云上的一个storage account，然后再通过storage account复制到目标订阅中的托管磁盘(静态加密)，初始复制完成后，会进入到增量复制的阶段，相当于基于上一次复制以来发生的所有数据更改会被打包复制并写入副本托管磁盘，确保托管磁盘数据和源VM保持同步。底层用的是VMware的CBT技术获得当前快照与上次成功的快照之间的更改，当然最后正式客户点迁移的那一刻，会最后进行一次数据校验，把剩余所有剩余的更改过的数据最后复制到托管磁盘，然后此时必须关闭本地VM，防止迁移过程有任何新增数据无法同步。
同时azure migrate也会有一个**数据校验的方式**，第一个是确确保每次复制周期同步上来的数据是一致性的，在增量备份阶段，我们会通过**将源磁盘划分成512字节的扇区，每个扇区都映射到bitmap中的一个bit**，同时，**在数据传输到azure的托管磁盘后，托管磁盘也会创建一个bitmap，最后会通过对比两个bitmap**，确保没有遗漏任何已更改的块，如果发现有任何不匹配的情况，当前复制周期会被视作为失败，那么在下一次复制周期，又会重新进行同步。第二个是会确保当前azure的**托管磁盘与源磁盘的数据是否相同**，简单来说就是每次已上传的数据都会被作为**blob进行压缩和加密后存储到存储账户中，并在压缩前计算此块的校验和(checksum)**，如果不匹配，则不会写入azure磁盘中，并且视为当前周期失败，和刚刚一样，在下一次复制周期，又会重新进行同步。
#### 复制周期逻辑讲解
复制周期的逻辑是先进行初次的完整复制，并在初次完整复制后马上进行第一个增量备份，下一个增量备份会通过一个公式，min[max[1 hour, (<Previous delta replication cycle time>/2)], 12 hours]，这个公式比较抽象，简单来说就是下一次周期会在上一次增量备份所花费的时间除以二，并且这个时间不会低于1小时也不会高于12小时。假如上一次增量备份花了8小时才完成，那下一次增量备份会在4小时以后进行。
然后最终我们才开始正式的迁移，当然迁移的背后，azure migrate会做一个叫hydration的过程，简单来说就是azure会临时起一台中介VM，把源盘挂上然后对驱动啊，代理什么的做必要的改动，再生成最终的VM。然后就是正式迁移了，正式迁移的过程中，因为是分批迁移，所以要确保先迁移上去的web vm啊，api啊还能和本地数据库连接，以及就是要确保把业务域名更换到客户云上的frontdoor等，当然最后最重要的数据库迁移，就还是会有一个短暂的停机，并且azure migrate再迁移前会做一次last sync，确保数据一致性，然后再正式迁移。因为我们是在他们美国团队的晚上去进行的，所以是用户活跃度最低的时候去做的迁移，大致的宕机窗口是20分钟左右。

关于hyper-V,就是基于Hyper-V replica去追踪每次磁盘的变化数据，并记录到log files(hrl文件)，这个log文件与磁盘是在同一个文件夹当中，每个磁盘都会有一个关联的hrl文件，会发送到云端的storage account，为每次增量备份去做一个追踪。

## 遇到的问题：
#### 网络：
1. 迁移网络遇到的问题：
当时一开始卡在私网复制出了问题，一开始是azure终端的private endpoint不联通，客户一直出问题的原因是他们在dns中加了一个forwarder到azure的public dns ip 168.63.129.16，然后一直还是nslookup出问题，当时我们因为迁移窗口短，所以是直接到host file上加映射IP和地址解决的，
2. 迁移后，IP发生改变，先前使用IP互相调用的应用会失联，怎么办？
    #### 情况一：用户本地可以将IP硬编码统一改成域名：
    1. 用FQDN取代硬编码，**本地DNS**服务器做域名解析**指向本地IP**。
    2. 在云端做好Azure private DNS Zone，并打通云端DNS resolver和本地的网络，在本地DNS做conditional forwarded。
    3. 降低TTL到60-300秒，预热缓存。
    4. 迁移日，把域名的权威解析/记录切换成云端IP/Private endpoint；客户端随TTL过期后自动指向新后端。
    #### 情况二：本地全面改代码代价太大：
    ##### A. NAT转换
    1. 本地放置一台NAT/防火墙设备(F5、Palo等等)，把目的地为旧IP流量引流到NAT，然后通过NAT做DNAT规则，比如旧IP:端口号指向新IP:端口号。
    2. 为避免回程不对称，对所有DNAT规则启用SNAT，把源改成NAT侧地址。
    3. 云端确保有Expressroute/VPN，VNet到本地的路由包含本地网段，允许回程到NAT的地址。
    ##### B. 反向代理/网关：
    1. 本地部署一台网关/代理(Nginx/F5)，对外仍监听旧IP/端口，转发到云端后端。
    2. 在代理上监听旧IP：端口并且后端指向新IP：端口。
    3. 云端部署ILB，将迁移上来的应用放入后端。

#### 割接问题：
1. 简单一点，看客户需要做蓝绿，还是灰度。
2. 蓝绿则就是比较简单，比如拿azure举例子，在云端准备好一个公网入口的形态，可以是Azure Front door(全球加速 + 权重/健康探测 + WAF，推荐),Azure application gateway(区域入口，四层配合公有 SLB)或者就是简单的公有load balancer(最轻，但没有 L7 能力；灰度靠上层或 Traffic Manager)。
3. 拿AFD举例子，在AFD准备两个入口，一个是你本地的公网出口(可能是一个反代理服务器)的公网地址，一个是你的云上公网地址，割切时，将权威DNS的对外域名改成CNAME指向AFD的endpoint，之后你就可以在AFD上切换优先级，把优先级改成云上公网地址。但在这之前你还要在AFD上做一些校验和配置等等，AFD需要确保这个域名是你的。
#### disk churn：
然后当时解决了PE解析的问题以后，最多的问题还是disk churn/iops超了限制，那么我们就是要去切换成high churn模式，把缓存数据的cache storage account改成premium block blob，这样单机可提升到100MB/s，当然还是有部分VM尤其是数据库本地磁盘churn太高了，我们当时就把复制压力分散到多个存储账户，避免单个账户的入口限速，当然还有一些磁盘就是高写入，那我们只能先去排除掉这些高churn磁盘，然后再做迁移，事后再去把剩余几个高churn的磁盘去单独做数据传输，除了单个disk churn的问题，还有就是客户客户复制超过300台VM，超出了单个appliance支持的上限，需要scale out appliance。
#### 宽带压力：
就是并行复制大量磁盘时，本地带宽压力比较大，所以也是分批去进行复制，并且也是改了VMware appliance上的限流策略，白天的时候限流100Mb/s，晚上放开,Hyper-V是通过C:\Program Files\Microsoft Azure Recovery Services Agent\bin\wabadmin.msc去调整限速策略。


