1. 四月份离职之后都在做什么？

    回答：
    四月份离职后，我主要集中在两个方面：一方面完成了学业收尾，另一方面系统化地补充和实践技能。我梳理了从企业架构迁移的关键方法论TOGAF，并在微软云上K8s 环境中搭建了一个web应用，GitOps/DeVops等实操演练，还写了脚本沉淀经验。同时，我考取了微软的 Azure Administrator Associate 和 Azure Solutions Architect Expert 两个证书，把理论和实战结合起来。整体上，这段时间让我形成了更完整的知识体系和可落地的工具，可以快速投入到实际项目中。

2. 主要负责微软云什么团队？

    回答：
    我所在的团队主要负责微软云的**数据保护与迁移方向**。团队的工作范围涵盖了从 **IaaS 层到 PaaS 层**的备份恢复，以及**本地与云之间的容灾与迁移场景**。具体包括 Azure 原生的**虚拟机、数据库、存储等资源**的备份与恢复，同时也涉及**混合云和本地环境**的数据保护解决方案。整个团队在微软内部被称为 ABRS（Azure Backup, Recovery, and Migration Services），而我在其中担任的是技术支持工程师，专注于帮助客户在数据保护与迁移场景中实现稳定、可扩展的落地方案。

3. 备份的产品有哪些？

    回答：
    简单来说，微软的备份体系既覆盖了云上全栈服务，IaaS 层包括 Azure 虚拟机备份，PaaS 层Azure 上的一些核心服务，例如 Blob Storage、Kubernetes。也能延伸到本地和多云场景，满足企业从文件、虚拟机到数据库、容器的多层次保护需求。

4. 虚拟机的备份，主要是解决什么问题？你是怎么做的？

    回答：
    虚拟机备份主要解决的问题是保障**业务连续性和数据可靠性**。一旦遇到硬件故障、系统崩溃或者操作失误，备份能够确保数据不会丢失，并且业务能在可接受的时间内恢复。
    具体来看，我会从三个方面来做：
    第一，**备份范围**。客户可以选择整机级备份，也可以选择文件级或应用级别的备份，范围不同，保护力度和成本也不同。
    第二，**备份策略**。会根据业务对恢复点目标（RPO）的要求来设计，比如每天一次、每小时一次，甚至接近实时的增量备份。同时还要考虑恢复时间目标（RTO），确保在故障后能尽快恢复。
    第三，**一致性保障**。我们通常区分三种：Crash Consistent，保证磁盘数据一致；File System Consistent，保证文件系统一致；以及 Application Consistent，它会让应用先把日志写入磁盘，再进行快照，这样恢复后应用可以直接运行。
    最后，虚拟机备份还需要结合定期的校验和恢复演练，比如每周或每月验证一次，确保备份真正能用。这样客户在遇到突发情况时，才能做到“有备可依，快速恢复”。

    

5. 按照正常to b业务来看的话，正常业务的这个需求不是应该他们自己团队的运维或者si来做吗？为什么会交给云方面技术上的？

    回答：
    从业务角度看，很多人会觉得企业应该由自己团队或 SI 来做日常运维，但实际上我们云厂商的技术支持依然非常必要。原因主要有三点：
    第一，客户差异化。大客户虽然有成熟的运维团队，但在使用过程中仍会遇到跨产品、跨平台的复杂问题，尤其涉及到**产品特性、Bug 或边界场景时**，需要我们厂商提供一手的技术支持。而中小型客户的运维力量通常有限，有时只有**一两名 IT 人员，他们需要依赖我们来提供最佳实践和完整方案**。
    第二，场景复杂性。客户的备份、容灾、迁移等场景往往跨**越本地、云端、混合架构，方案**设计不仅仅是“装一个产品”这么简单，而是涉及到 **RPO、RTO、一致性校验等全局考虑**。这些只有**云厂商才能结合底层能力给出权威指导**。
    第三，价值延伸。我们不仅解决问题，还会帮助客户**做演练和优化**。例如在测试环境中模拟真实生产场景，验证完整的备份和恢复流程，确保方案在客户上生产时是可落地、可验证的。
    所以，客户之所以选择把部分工作交给我们，并不是因为他们不能做，而是因为我们能提供更系统、更深入的支持，让他们的**IT 投资风险更低、可靠性更高**。



6. 对理解，那像这种，这种直接对用户或者做毕业的这种需求解决的话，你一天能处理多少？

    回答：
    其实这个数量并不是固定的，要看工单的复杂度和客户场景。但整体来说，我每天大概会处理 3 到 4 个新进工单，其中可能包含 1–2 个一对一的深度技术支持，也可能是 一两个相对简单的 K 类案例。B 端客户的需求差异比较大，有些涉及架构设计和数据一致性保障，会占用更多时间；有些是常规操作类问题，处理效率会更高。整体节奏相对平衡。

    呃，这个其实是不一定的，但是我们一天大概能接三到四个新的工单，然后呃，可能嗯，每天的工单的这个困难程度或者客户的这个呃问题的scope都不一样，那如果说您说这种to b的话，我觉得呃一天至少也得有那么一两个121个一个左右一两个就是不确定，因为这个也不是每天他来的。K案例也不一定，所以大概可能一天一两个的样子。

7. 除了每天接案例，还会干其他事情吗？

    回答：
    除了日常处理客户案例，我还承担了一些额外的职责。

    第一，**新人培养**。随着工作经验的积累，我负责指导团队新成员，包括陪同他们做产品 ready 流程、帮他们过 checkpoint，并带领他们参与一线案例的分析。

    第二，**知识沉淀与分享**。我会在团队内部做经验分享，每周有区域级别的交流，每月会参与全球技术团队的知识分享，把常见问题和最佳实践沉淀下来，帮助团队整体提升。

    第三，**持续学习与实验**。在工作之外，我个人也会搭建一些实验环境，例如基于 Edge 的 VM 集群和小规模 K8s，模拟生产场景，尝试新的工具和方法。这样既能提升个人能力，也能在遇到客户复杂问题时提供更贴近实战的解决方案。

    总结来说，我的工作不仅是解决问题，还包括培养新人、分享经验、推动知识体系建设，并保持技术前沿的探索。

    其他其实嗯，因为随着后面我的这个嗯就是工作中的话可能呃我后面也会逐步的负责。就是呃，就是大概一年之后，我也逐步负责去培养一些我们组来的一些新人，因为每个人进来可能都会先从ready产品开始，比如说备份灾难迁移，它会一步一步ready，那可能我到一年之后，呃，我这三个产品都ready完了。然后我会负责去带一些新人，比如说嗯，去帮他们过一些，check point啊，以及就是我后面其实也负责过我们组的一个面试的一些呃，一些可能一面二面可能是我去负责那除了这以外，呃我们还会涉及到，就是有一个组内的一个经验分享，能每周会呃组内有一个分享，然后每周呃有两次组内分享，有一次是跟全球的这个我们这个这个团队，因为我们团队可能不仅我们亚洲时区有可能美国时区、欧洲时区都会有，印度时区也会有，所以还会有一个每周一次的一个就是全球呃全球的一个技术团队的一个知识分享，然后可能呃我们组内的团队分享，我可能也会定期会去呃总结一下，我这一周可能学了一些什么新的知识，或者发现了一些什么呃新的一些trouble的方法，然后会定期去做一些分享。
    除此之外呢，我们私底下其实我自己也会比较倒喜欢喜欢倒腾嘛。就是虽然我们组只负责这几的产品，但是我可能对云计算会比较。呃喜欢会比较就是喜欢，那么我会可能自己私底下会去edge上搭一些就是自己的一些应用。我可能之前之前呃帮组内搭过一个组内的一个工具呃，是基于edge的vms，上面搭了一个小的一个kys集群，然后也玩了一下，edge， divorce那一套，然后可能就是自己私底下也会学一些，然后也会分享到呃我们的组内呃，大概可能是这样的。  

8. 你刚才是说在做相关的这个迁移致性的时候，其实这块我想问，就是说你这个一致性怎么保证呢？有哪些方案方式去验证迁移或者是备份容灾这个一致性的内容是保持一致的，比如说你的数据，你的存储这块用什么方法去验证？

    回答：
    在迁移或备份场景中，数据一致性验证是确保可靠性的核心环节。常见的方法可以从三个层面来看：
    **底层校验（Block/Bitmap 验证）**
    增量备份后，系统会自动生成数据块的校验信息，比如哈希或位图（bitmap）。恢复端会对比源端与目标端的位图，确保没有丢失或错误的块。如果发现差异，就会重新传输或提示失败。
    **文件与存储层校验**
    对于数据库或文件型数据，常见做法是通过 checksum/MD5 校验 来比对文件是否一致。比如数据库迁移后，会在源端和目标端生成 checksum，再逐一比对，确保表级或文件级的数据完整。
    **应用与业务层校验**
    在关键应用（如数据库系统）中，还需要做更高层次的验证。比如：
    应用一致性校验：**通过事务日志（log）、binlog、WAL 等机制验证是否丢失数据。**
    业务校验：**在恢复端执行样本查询或功能性测试（例如订单查询、库存统计）**，确认业务逻辑正常。
    此外，为了提升可靠性，企业通常会结合 **定期演练（如恢复测试、容灾切换演练）**，在真实环境下验证备份的可用性，避免一致性只停留在校验通过的层面。

    就是如果说嗯，我们特就是特定指的是这个叫什么？呃，迁移这一部分。呃。那么呃，就是迁移，这部分其实就是可能相比备份要复杂一点，可能它的环境并不是一个在云源本身，它可能是本地的一个。我们说可能是数据库，那么其实呃，总体上，嗯，不管是迁移也好，呃备份也好，它总体上还是呃两个东西，其实说白了就是一个是呃，第一次去做一个全叫第一次去做一个整体的一个全面快照的备份，然后后续采用一个增量备份的模式去保证一个数据一致性。
    当然呃，可能它底层呃会有一个数据校验的一个方式，就呃就比如说呃，就比如说我们拿我们这个微软的这个呃迁移的这个方式去说，那么就是呃它底我们，我们迁移它会有两个，一个数据校验的过程，那第一个呃，它会，其实就是相当于本地它会这个工具会在本地的这个数据磁盘划分成一个512自己的一个扇区。呃，每个扇区它会对应到一个bat mat里面，那么呃，云端云端备份的这个磁盘，它也会划分一个，就是同样的一个扇区，然后每个扇区可能也会创建一个bat mat，然后最终这个工具它最后底层会去校验这两个bit map之间的一个呃，去对比一下，然后确保它没有遗漏任何已更改的一个模块。
    那么如果有已更改的，有已更改的模块，比如说source，他会发现一个模块，哎，没有更新到云上，那么这个时候他可能就是会判断这次呃，这次的一个备份的数据一致性是不成功的，他就会判断这是备份失败了。呃，那么除此之外，可能还会有第二就是第二种就是通过check some去校验，就包括，比如说你要把一个数据备份到一个呃，比方说云端，我们，我们把它储存到一个blog里面，那么它会把这个数据压缩到里面，之后会呃产生一个，check some，那么它会和呃压缩前的那个check项目去做一个进行一个匹配。
    呃，如果说不匹配的话，那他也是会校验说哎，这次备份失败了，那么他会。呃去判断这次失败，那么他会给你一个。呃，返回一个嗯，结果。呃当然呃，除了这些底层的一些校验以外，就大概大概率不太可能。就是可能底层它这个校验就是没发现，然后最后客户发现数据呃不见了，那当然也会有这种情况，那可能会需要一些人工的去校验，那当然最简单的方式可能我们就是客户，他就像刚刚说的，他可能去测试备份，他可能用之前的一个恢复点进行一次恢复，然后人工的去对比一下上面的一些文件，或者是一些呃磁盘的大小等。
    他可能人工的一个方式去校验当那如果是数据库的话，他可能还有比方说mysql，他可能会去呃blog，去对比一下之类的。当然，呃，这种情况是不太可能，因为它底层的这个代码其实已经写好了，就是如果这两个不成功，是不可能完成这次备份，所以说大概率呃，就是就这个云原生的备份应该不会出现这个数据不一致的情况。

9. 对那ok，那我问那我最后再问两个问题，第一个就是如果说文件数量特别大，比如说有可能你单个的一个盘上面挂了几千个几千万个小文件，如果你要做这种文件备份的话，这种大批量的这种迁移，你怎么保持怎么确保他的文件一致性和那个顺序一致性？和第一个。那么第二个问题，你说你也在做了一些k8s的一些用的这个事情，那你最后用k8s的事情去解决了你的业务上的一些什么问题，两个是这两个问题。你case，你可以也是简单的简单一下。

但是你的工具工具的那个，比如说你要用一些标准的一些命令和工具的话，它的可能最大的选择范围是有限的，因为你现在用最好用，比如比如说自己写的或者第三方的一些能力去一次性操几万的文件，他光建立一个所有列表都有可能会把内存pass那你现有的工具里面，如果一次性操作几千万个文件的话，你有没有试验过或者是怎么挑战过他的这个工具性能的这个局限呢？

    回答：
    当面对海量小文件（比如单盘几百万甚至上千万文件）的备份时，单纯依赖文件级操作会有性能瓶颈，因此主流做法是基于磁盘快照（block-level snapshot）来进行全量和增量备份。
    第一次会生成一个完整快照，后续通过位图（bitmap）机制只记录变化的数据块。恢复时系统会对源端和目标端的位图进行比对，从而确保增量数据的完整性和一致性。这样即使是千万级的小文件，也能通过块级操作高效保证数据正确。
    至于工具的限制，确实存在。如果仅依赖传统文件操作，效率低下且容易受限于文件系统元数据的处理能力。而块级方案突破了单次文件操作的性能瓶颈，但它也要求底层存储和快照机制足够健壮。所以，在实际项目中，通常会结合 块级快照 + 校验机制 + 周期性恢复演练，来确保大规模文件的一致性和可靠性。

    嗯嗯，那我可以就是，如果说就是我们还是基于一个快照的，一个就磁盘快照的方式去思考一个备份和迁移，其实可能嗯，可能就是他只会就是他的，他的这个维度可能是在磁块就磁盘上面呃，那么就比如说他磁盘就是就可能他磁盘里面可能存了就包括上千万个文件，那么其实在拍快照的时候，他可能不会去考虑。就是，哎，你这上面到底存了多少文件，他可能就是基基于你当前的一个磁盘去进行一个完整的快照，那么。嗯，其实这种情况下，嗯，除非是可能有用户用那种就是呃，不是磁盘的这个维度的这个方式去进行备份，他可能是基于他要去备份呃文件夹和文件的这个这个这个维度去进行备份，那可能这个时候可能我们会有这种呃上千万个文件的这个这个复杂程度，但一般情况下，我们可能会推荐客户做一个整机备份，就是呃，直接会给他的磁盘进行一个快照，包括后续的一个增量备份那。
    呃，那如何去确保它的一致性的话。呃，还是刚刚可能提到我们呃要就是后，就是除了第一次去做一个完整快照，后续还要去持续的做增量的备份就是包括去呃，增量备份就是相当于就是把它呃当前的和上一次备份中间产生的一些数据差和增长增减增删改减这些变化数变化的这些数据块就是block呃，给它就是把这一个增量的一些数据给它同步到这一次的增量备份。那么通过这种，这种这种方式可能去保证它的一个呃文件一致性，我不知道，就是可能这个有没有，就是达到您想要问的这个问题也是一个办法，

    k8s相关：
    在日常接客户案例之外，我还承担了一些团队和流程优化的工作。
    首先是 案例分配和 SLA 优化。随着案例量增加，如果仅依赖人工分配，效率会很低，甚至导致 SLA 不达标。我在团队中尝试通过脚本和小工具，结合 Edge 平台的数据，优化了分配逻辑，让案例能够更公平、高效地分派到不同成员，避免新人和资深工程师之间的不均衡。
    其次是 知识沉淀和分享。我会把典型案例的解决方法总结成文档，沉淀到知识库里，并在团队内做分享。这既帮助新成员快速上手，也提升了整体交付的一致性。
    最后是 持续学习和实验。我个人利用业余时间在本地搭建了小型 K8s 集群，实践部署与恢复的流程。这既是为了提升自己对云原生的理解，也希望未来能把这种探索经验带回团队，帮助优化我们的支持手段。


    对，呃，其实这个这个其实不是我们的职责，也不是我们工作要求。这个最开始的趋势，趋势背景就是因为呃，因为是这样，我可以可能呃快速讲一下我们的一个每天工作的一个流程，其实我们每天会有一个q，这个q里面会进呃，可能客户的案例可能一天会进三四十个，或者忙的话可能上百个都有可能。然后这个时候我们组会有特定去分这些案例的人，那么我们管他叫ta或者qa，然后他会根据我们组每个人的一个ready程度，就像刚刚可能提到有新人他可能刚进来，他只他只他只ready的备份这一个产品，那么肯定就不能给他分迁移的产品的案例，或者是灾备的。
    那么呃，相当于就是我们的qa和ta要去进行一个手动分配，分配就是包含，就是可能呃，要根据每个人ready程度去分配，那我最开始呃就会觉得这样效率非常低下，因为呃，我们随着组内的人越来越多了，其实后期就经常会出现那种哎，有的人他还没有ready这个产品，但是可能ta分给了他，然后就导致，呃，很有可能导致我们我们每个case会有个SLA，就比如说客户，呃，跟客户保证这个case要三小时内回复，那么这个时候接到这个案例的同学可能没有ready，然后又去跟ta去对去沟通，又耽误了时间，导致了当时可能有很多案例，他的SLA没有meet上，那客户就肯定不满意嘛。
    那还有就是可能就是我们组内就是这个分配的不够平均。那可能有的有的人他觉得ata觉得你比较厉害，让他更多分一点给你，那这样渐渐可能有些人会觉得这样不公平，所以说当下呢，我其实就呃，就是正好有edge这个，这个平台我们是每个月有一个大概1000美金的额度，所以说呃，我就自己想去尝试一下，看能不能做一个工具能够改善一下这个手动分配的一个流程。呃，也基于一个自己想去学习一下k8s也好，或者是这几年比较流行去运开发，deo， s也好，所以想也抱着一个学习的角度，然后也想说，能不能正好也能帮一下团队这么一个背景，下午去做的这个事情，对I。
