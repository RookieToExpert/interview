## 准备变量
LB IP以及创建monitor的namespace
```bash
export LB_IP=20.227.119.95
kubectl create namespace monitoring
```
## 下载helm包管理
```bash 
# 1) 下载官方安装脚本
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
# 2) 赋执行权限
chmod 700 get_helm.sh
# 3) 执行安装（会自动下载匹配你平台的二进制到 /usr/local/bin/helm）
./get_helm.sh
# 4) 验证
helm version
```
## 更新HELM仓库
添加普罗米修斯的库
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```

## 初始化Grafana 初始账号密码
```bash
echo -n 'ray' > ./admin-user
echo -n 'suckmydick' > ./admin-password
kubectl create secret generic grafana-admin-credentials \
  --from-file=./admin-user --from-file=./admin-password -n monitoring
rm ./admin-user ./admin-password
```

## 给 ingress-nginx Service 增加 metrics 端口（10254）
```bash
kubectl -n ingress-nginx patch svc ingress-nginx-controller \
  --type='json' \
  -p='[{"op":"add","path":"/spec/ports/-","value":{"name":"metrics","port":10254,"protocol":"TCP","targetPort":10254}}]'
```

## 保存增强版（不开持久化）
把下面整段保存为 values.yaml（把 <LB_IP> 换成 20.227.119.95，或先 export LB_IP 再用 sed 渲染也行）。
```bash
vim values.yaml
# ==== 统一默认规则（更丰富的预置告警/录制规则），屏蔽 etcd 相关以免噪声 ====
defaultRules:
  create: true
  rules:
    alertmanager: true
    # etcd 常需要证书与自定义 endpoints，kubeadm 默认不方便采集，先关：
    etcd: false
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

# ==== Alertmanager（先开组件，暂不暴露 Ingress；以后要告警再配置接收器）====
alertmanager:
  enabled: true
  ingress:
    enabled: false

# ==== Grafana：启用默认看板 + 从 Secret 读取初始管理员账号 ====
grafana:
  enabled: true
  defaultDashboardsEnabled: true
  # 内置的数据源/看板会自动导入，无需手工导入 JSON
  service:
    type: ClusterIP
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - grafana.20.227.119.95.nip.io
    path: /
    pathType: Prefix
  admin:
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    passwordKey: admin-password
  persistence:
    enabled: false   # 先不开持久化；后续加 SC 再打开即可

# ==== apiserver / kubelet / kube-state-metrics / node-exporter ====
kubeApiServer:
  enabled: true

kubelet:
  enabled: true
  serviceMonitor:
    # 用 node 名替换 instance 标签，Grafana 看板上更直观
    metricRelabelings:
      - action: replace
        regex: (.*)
        replacement: $1
        sourceLabels: [__meta_kubernetes_pod_node_name]
        targetLabel: instance

kubeStateMetrics:
  enabled: true
  selfMonitor:
    enabled: true
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: kubernetes_node

nodeExporter:
  enabled: true
  extraArgs:
    # 过滤掉无意义的伪文件系统，避免磁盘面板噪声
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)(/|$)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tmpfs)$
  service:
    portName: http-metrics
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: kubernetes_node

prometheusOperator:
  enabled: true

# ==== Prometheus 本体（不开持久化；先用空目录即可）====
prometheus:
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - prometheus.20.227.119.95.nip.io
    path: /
    pathType: Prefix
  prometheusSpec:
    replicas: 1
    retention: 12h        # 开持久化前这里只是控制 in-memory/emptyDir 的保留时间
    walCompression: true

# ==== Kubernetes 其他组件的采集 ====
# kubeControllerManager / kubeScheduler / kubeEtcd 在 kubeadm 上通常需要 https 认证或手配 endpoints。
# 先保持默认（不强开），等你以后需要再单独加 endpoints 与证书。
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeEtcd:
  enabled: false

# ==== 把 ingress-nginx 纳入采集（依赖我们给 svc 加的 10254 端口）====
additionalServiceMonitors:
  - name: ingress-nginx-monitor
    namespaceSelector:
      matchNames: ["ingress-nginx"]
    selector:
      matchLabels:
        app.kubernetes.io/name: ingress-nginx
    endpoints:
      - port: "metrics"


# 用变量渲染也行：
sed "s/<LB_IP>/$LB_IP/g" values.yaml > values.rendered.yaml
```
#### 因为上面资源需求大，换成下面这个：
```bash
# ==== 预置规则（常用监控规则全开；避免 kubeadm 证书坑，关 etcd/kcm/scheduler）====
defaultRules:
  create: true
  rules:
    alertmanager: true
    configReloaders: true
    etcd: false
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

# ==== Alertmanager（调度到 worker；不暴露 Ingress）====
alertmanager:
  enabled: true
  ingress:
    enabled: false
  alertmanagerSpec:
    nodeSelector:
      node-role.kubernetes.io/worker: ""
  resources:
    requests: { cpu: "30m", memory: "64Mi" }

# ==== Grafana（走 Ingress；仅 worker；先不开持久化）====
grafana:
  enabled: true
  defaultDashboardsEnabled: true
  service:
    type: ClusterIP
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - "grafana.20.227.119.95.nip.io"
    path: /
    pathType: Prefix
  # 如你未预先创建 admin Secret，删除 admin.* 三行，使用 chart 默认管理员并首登改密
  admin:
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    passwordKey: admin-password
  persistence:
    enabled: false
  resources:
    requests: { cpu: "50m",  memory: "128Mi" }
    limits:   { cpu: "500m", memory: "512Mi" }
  nodeSelector:
    node-role.kubernetes.io/worker: ""

# ==== API Server / Kubelet / KSM（仅 worker）====
kubeApiServer:
  enabled: true

kubelet:
  enabled: true
  serviceMonitor:
    # 把 node 名映射到 instance 标签，便于看图表
    metricRelabelings:
      - action: replace
        regex: (.*)
        replacement: $1
        sourceLabels: [__meta_kubernetes_pod_node_name]
        targetLabel: instance

kubeStateMetrics:
  enabled: true
  selfMonitor:
    enabled: true
  prometheus:
    monitor:
      enabled: true
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: kubernetes_node
  resources:
    requests: { cpu: "30m", memory: "128Mi" }
  nodeSelector:
    node-role.kubernetes.io/worker: ""

# ==== Node Exporter（DaemonSet；仅 worker）====
prometheus-node-exporter:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
  resources:
    requests: { cpu: "20m", memory: "64Mi" }
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)(/|$)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tmpfs)$

# kubeadm 默认这三类需要额外证书/端点，先关
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeEtcd:
  enabled: false

# ==== Operator（仅 worker）====
prometheusOperator:
  enabled: true
  resources:
    requests: { cpu: "50m", memory: "128Mi" }
  nodeSelector:
    node-role.kubernetes.io/worker: ""

# ==== Prometheus（走 Ingress；仅 worker；先不开持久化）====
prometheus:
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - "prometheus.20.227.119.95.nip.io"
    path: /
    pathType: Prefix
  prometheusSpec:
    replicas: 1
    retention: 12h
    walCompression: true
    resources:
      requests: { cpu: "150m", memory: "256Mi" }
    nodeSelector:
      node-role.kubernetes.io/worker: ""

# ==== 采集 ingress-nginx（要求其 Service 已有名为 metrics 的 10254 端口）====
additionalServiceMonitors:
  - name: ingress-nginx-monitor
    namespaceSelector:
      matchNames: ["ingress-nginx"]
    selector:
      matchLabels:
        app.kubernetes.io/name: ingress-nginx
    endpoints:
      - port: "metrics"
```
## 安装普罗米修斯通过values文件
```bash
helm install prometheus prometheus-community/kube-prometheus-stack \
  -n monitoring -f values.yaml
```

## 验证
```bash
kubectl -n monitoring get pods -o wide
kubectl -n monitoring get ingress
kubectl -n monitoring get endpoints prometheus-grafana -o yaml | sed -n '1,80p'
```

## 删除重新来过
```bash
# 1) 看当前 release
helm -n monitoring list

# 2) 卸载 kube-prometheus-stack（release 名我一直用的是 prometheus）
helm uninstall prometheus -n monitoring

# 3) 可选：把 monitoring 命名空间也删掉，获得“全新”环境
kubectl delete ns monitoring

# 4) 等命名空间真的消失（终态 Terminating -> Gone）
kubectl get ns
```

## 把 master 允许调度（开放权限）
找到你的 master 名（你之前的是 k8s-mast71grrw）
```bash
# 看看当前 taint
kubectl describe node k8s-mast71grrw | sed -n '/Taints:/,/Conditions/p'

# 移除默认的 NoSchedule taint（两种 key，执行都安全）
kubectl taint nodes k8s-mast71grrw node-role.kubernetes.io/control-plane:NoSchedule-  || true
kubectl taint nodes k8s-mast71grrw node-role.kubernetes.io/master:NoSchedule-        || true
###（可选）之后想恢复“master 不接活”
kubectl taint nodes k8s-mast71grrw node-role.kubernetes.io/control-plane=:NoSchedule
```