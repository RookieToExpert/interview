- **云上有哪些网络产品**
    - **连接类**：VPC，专线，VPN网关，跨区域互联
    - **访问控制类**：安全组，网络ACL，私有链接（Private Link）
    - **流量调度与传输类**：负载均衡（SLB/ELB），应用网关（API Gateway / Application Gateway），CDN
    - **安全与防护类**：防火墙，DDoS 防护，WAF（Web 应用防火墙）

## 成本
- **云计算成本优化在架构和组件选型上的思考？**
    - **业务维度**
        - 业务核心需求
    - **成本维度**
        - 计算
        - 存储
        - 网络
    - **技术维度**
        - 托管优先paas
        - 弹性——容器k8s，高吞吐——Redis，Memcached，kafka，rocketMQ
    - **时间维度**
        - 短期
            - 价格优先
        - 长期
            - 混合云多活架构
    
- **如何预测和规划成本的思路和具体使用的工具？**
    - 思路：
        - 历史趋势分析
        - 业务周期规律
        - 异常检测与弹性策略
    - 工具：
        - 云原生监控工具
        - 开源工具
        - 自研/脚本
    - 落地：
        - 业务驱动预测
        - 基础资源预测
        - 配合弹性伸缩和预算做规划
- **成本规划中，除了考虑资本利用率，还考虑什么？**
    - 业务需要
        - 低延迟和高吞吐，即使利用率低也需保持冗余
        - 可靠性与冗余
        - 容量与弹性
    - 成本结构
        - 不同计费模式(按需，预留，spot)
        - 运维人力成本

- **对数据分析和成本可视化治理如何理解？**
    - 数据建模
        - 历史监控数据通过**统计模型或机器学习**建立映射关系
            - 常见机器学习有回归模型、随机森林、XGBoost 来做多维预测
        - **方法上**可以用 **时序预测（ARIMA、Prophet） 或 回归/聚类** 来识别资源使用规律和异常波动。
            - 常见算法有 ARIMA、Holt-Winters、Prophet
        - 产出结果
    - 看板建模
        - 可视化
            - 资源层
            - 成本层
            - 预测层
        - 治理落地
            - 规则
            - 阈值
- **多活和数据高可用如何理解**
    - 多活目的
    - 高可用关键：
        - 复制机制
        - 一致性与延迟权衡
        - 存储层冗余
    - 实现方式：
        - 数据库层：跨可用区域多副本
        - 缓存/队列层：多节点分片 + 自动故障转移
        - 流量层：全局流量调度

- **如何保证双活不腐化？是独立的(双活架构的治理问题)**：
    - 流量治理
    - 数据层治理
    - 运维与演练
    - 独立运维团队

- **如何保证两个机房不是互相依赖的？**：
    - 业务层解耦
    - 数据层解耦
    - 基础设施和运维解耦

- **如何治理跨机房流量**：
    - 分类治理：
        - 强一致数据
        - 弱一致数据
        - 缓存/消息队列
    - 技术手段
        - 路由与调度
        - QoS 与限流
        - 压缩与合并
    - 监控与治理闭环


8. 虚拟机的备份，主要是解决什么问题？你是怎么做的？
    
    **答案**：
    > 简单回答→备份范围→备份策略→快照类型→恢复演练

    虚拟机备份主要解决的问题是保障**业务连续性和数据可靠性**。一旦遇到硬件故障、系统崩溃或者操作失误，备份能够确保数据不会丢失，并且业务能在可接受的时间内恢复。
    具体来看，我会从三个方面来做：
    第一，**备份范围**。客户可以选择整机级备份，也可以选择文件级或应用级别的备份，范围不同，保护力度和成本也不同。
    第二，**备份策略**。会根据业务对恢复点目标（RPO）的要求来设计，比如每天一次、每小时一次，甚至接近实时的增量备份。同时还要考虑恢复时间目标（RTO），确保在故障后能尽快恢复。
    第三，**一致性保障**。我们通常区分三种：Crash Consistent，保证磁盘数据一致；File System Consistent，保证文件系统一致；以及 Application Consistent，它会让应用先把日志写入磁盘，再进行快照，这样恢复后应用可以直接运行。
    最后，虚拟机备份还需要结合定期的校验和恢复演练，比如每周或每月验证一次，确保备份真正能用。这样客户在遇到突发情况时，才能做到“有备可依，快速恢复”。

9. 如何保证数据一致性？

    **答案**：
    > 底层校验→文件和存储层校验→应用层校验→业务校验

    在迁移或备份场景中，数据一致性验证是确保可靠性的核心环节。常见的方法可以从三个层面来看：
    **底层校验（Block/Bitmap 验证）**
    增量备份后，系统会自动生成数据块的校验信息，比如哈希或位图（bitmap）。恢复端会对比源端与目标端的位图，确保没有丢失或错误的块。如果发现差异，就会重新传输或提示失败。
    **文件与存储层校验**
    对于数据库或文件型数据，常见做法是通过 checksum/MD5 校验 来比对文件是否一致。比如数据库迁移后，会在源端和目标端生成 checksum，再逐一比对，确保表级或文件级的数据完整。
    **应用与业务层校验**
    在关键应用（如数据库系统）中，还需要做更高层次的验证。比如：
    应用一致性校验：**通过事务日志（log）、binlog、WAL 等机制验证是否丢失数据。**
    业务校验：**在恢复端执行样本查询或功能性测试（例如订单查询、库存统计）**，确认业务逻辑正常。
    此外，为了提升可靠性，企业通常会结合 **定期演练（如恢复测试、容灾切换演练）**，在真实环境下验证备份的可用性，避免一致性只停留在校验通过的层面。

10. 如果应用有上千个文件，该怎么做？
    
    **答案**：
    > 基于磁盘快照→磁盘校验方式→结论

    当面对海量小文件（比如单盘几百万甚至上千万文件）的备份时，单纯依赖文件级操作会有性能瓶颈，因此主流做法是基于磁盘快照（block-level snapshot）来进行全量和增量备份。
    第一次会生成一个完整快照，后续通过位图（bitmap）机制只记录变化的数据块。恢复时系统会对源端和目标端的位图进行比对，从而确保增量数据的完整性和一致性。这样即使是千万级的小文件，也能通过块级操作高效保证数据正确。
    至于工具的限制，确实存在。如果仅依赖传统文件操作，效率低下且容易受限于文件系统元数据的处理能力。而块级方案突破了单次文件操作的性能瓶颈，但它也要求底层存储和快照机制足够健壮。所以，在实际项目中，通常会结合 块级快照 + 校验机制 + 周期性恢复演练，来确保大规模文件的一致性和可靠性。

1. 本地进程之间通过IP调用，如果迁移上云，IP发生改变，怎么办？
2. 如何保证数据一致性？
3. 是否使用过一些开源的数据库迁移工具？
4. 你的核心技术栈是什么？
5. 新的环境进程起不来、报错，哪几个方面排查？
6. 服务器部署划分到不同机房，每个机房部署相同服务还是部署不同服务比较好？
7. SLA，SLO，SLI是什么？

    **答案**：
    - **SLA（Service Level Agreement）**：合同/协议，写进法律文件里的承诺，通常是厂商对客户的。
    - **SLO（Service Level Objective）**：目标值，是架构师/运维团队设定的期望，比如 API 成功率 ≥ 99.9%。
    - **SLI（Service Level Indicator）**：实际指标，监控采集到的数据，比如“8月API成功率 = 99.93%”。

